{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Day 2: Into the World of (ir)Rationality\"\n",
        "author: \n",
        "  - name: Devjyoti Chakrabarti\n",
        "    affiliation: University of Oxford \n",
        "format: \n",
        "     revealjs:\n",
        "      theme: default\n",
        "      incremental: true \n",
        "---"
      ],
      "id": "68bb015d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "\n",
        "[Shepard tables](https://en.wikipedia.org/wiki/Shepard_tables){style=\"text-decoration:none\"}\n",
        "\n",
        "![](images/clipboard-4091288017.png){fig-align=\"center\"}\n",
        "\n",
        "</div>\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "<div>\n",
        "\n",
        "#### What animal do you see in the image?\n",
        "\n",
        "![](images/clipboard-3011836111.png){fig-align=\"center\"}\n",
        "\n",
        "</div>"
      ],
      "id": "53b8f4b2"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<div>\n",
        "\n",
        "#### Is the dot on the front or in the back of the cube?\n",
        "\n",
        "![](images/clipboard-432469204.png){fig-align=\"center\"}\n",
        "\n",
        "</div>\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "::: {.incremental style=\"font-size: 0.875em\"}\n",
        "### Rationality\n",
        "\n",
        "-   When faced with choices, individuals choose the option which derives them the maximum possible benefit or utility.\n",
        "\n",
        "-   Our Homo-Economicus solves $$ \\underset{x_i^t \\in X_i}{\\text{max}} \\sum_{t=0}^{\\infty} \\delta^t U(x_i^t)$$ $\\delta:$ Discount Factor\n",
        "\n",
        "    $U(\\cdot):$ Utility Function\n",
        "\n",
        "    $X:$ Set of consumption bundles\n",
        ":::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "::: {.nonincremental style=\"font-size: 0.875em\"}\n",
        "Assumptions about the agent:\n",
        "\n",
        "1.  has well defined preferences and beliefs\n",
        "\n",
        "    -   unlimited willpower\n",
        "\n",
        "    -   purely self-interested\n",
        "\n",
        "2.  can make optimal choices given their preferences and beliefs\n",
        "\n",
        "    -   unlimited cognitive abilities\n",
        ":::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "::: {.nonincremental style=\"font-size: 0.875em\"}\n",
        "Possible relaxations of standard model to accommodate humans:\n",
        "\n",
        "1.  Bounded Willpower\n",
        "\n",
        "    -   Time preferences: $\\delta$ might not be stable\n",
        "    -   Risk preferences: $U(x_i|r)$ outcomes compared to some reference point $r$\n",
        "\n",
        "2.  Bounded self-interest\n",
        "\n",
        "    -   Social preferences: $U(x_i, x_{-i})$ agents care about others' outcomes $x_{-i}$\n",
        "\n",
        "3.  Bounded Rationality\n",
        "\n",
        "    -   Limited attention, sensitivity to framing, reliance on heuristics\n",
        ":::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "<div>\n",
        "\n",
        "### Bounded Willpower\n",
        "\n",
        "-   \"Even when given an understanding of the optimal choice, people will often still preferentially choose whatever brings the most short-term benefit over incremental progress toward a long-term goal.\"[^1] \n",
        "\n",
        "-   Examples: procrastination (\"will start tomorrow\"), smoking\n",
        "\n",
        "</div>\n",
        "\n",
        "[^1]: <https://news.uchicago.edu/explainer/what-is-behavioral-economics>\n",
        "\n",
        "---"
      ],
      "id": "63b97205"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "\n",
        "### Time discounting \n",
        "\n",
        "-   We value the future less than the present. Conversely, we tend to overweight the present compared to any period in the future, i.e. we are “present-biased”.\n",
        "\n",
        "-   Example: Saving decisions\n",
        "\n",
        "    People would rather take £110 in 35 days over £100 in 30 days.\\\n",
        "    But they would prefer to take £100 now over £110 given 5 days later.\n",
        "\n",
        "</div>"
      ],
      "id": "257d4f54"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<div>\n",
        "\n",
        "### Bounded Self-interest\n",
        "\n",
        "-   \"People are often willing to choose a less-optimal outcome for themselves if it means they can support others.\"[^2]\n",
        "\n",
        "-   They care, or act as if they care, about others, even strangers, in some circumstances.\n",
        "\n",
        "-   Examples: charity donations, volunteering\n",
        "\n",
        "</div>\n",
        "\n",
        "[^2]: <https://news.uchicago.edu/explainer/what-is-behavioral-economics>\n",
        "\n",
        "---"
      ],
      "id": "5d00c22d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "\n",
        "print(random.randrange(1,10))"
      ],
      "id": "21f4c7c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.incremental style=\"font-size: 0.875em\"}\n",
        "### Framing Effects\n",
        "\n",
        "Tversky & Kahneman (1981)\n",
        "\n",
        "Imagine that the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimate of the consequences of the programs are as follows:\n",
        "\n",
        "-   Program A: 200 people will be saved\n",
        "\n",
        "    Program B: $1/3$ probability 600 will be saved, $2/3$ probability that no people will be saved\n",
        "\n",
        "-   72 percent choose Program A and 28 percent choose Program B \\[N=152\\]\n",
        ":::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "<div>\n",
        "\n",
        "-   Program C: 400 people will die\n",
        "\n",
        "    Program D: $1/3$ probability nobody will die, $2/3$ probability that 600 people will die\n",
        "\n",
        "-   22 percent choose Program C and 78 percent choose Program D \\[N=155\\]\n",
        "\n",
        "</div>\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "<div>\n",
        "\n",
        "### CAVEATS!\n",
        "\n",
        "-   Adding non-standard assumptions does not imply an abandoning of traditional methods\n",
        "\n",
        "-   Despite limits to their empirical validity and applicability, they are sometimes appropriate (even if not exactly right)\n",
        "\n",
        "-   Old models get certain things wrong but they also get many things right\n",
        "\n",
        "-   Our goal is to integrate behavioural economics into mainstream economics\n",
        "\n",
        "</div>\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "::: {style=\"font-size: 0.775em; text-align: justify\"}\n",
        "### Expected Utility Theory\n",
        "\n",
        "-   Consider the following bet. A fair coin is tossed, if it lands on heads I pay you 10 pounds. However, if it lands on tails you have to pay me 10 pounds. What is your expected payoff\n",
        "\n",
        "    from playing in this bet? -\n",
        "\n",
        "-   $$\n",
        "    \\begin{align*}\n",
        "       \\text{Expected Value} &= Pr(Heads) * Payoff(Heads) + \\\\\n",
        "    & Pr(Tails) * Payoff(Tails) \\\\\n",
        "    &= 0.5 * 10 + 0.5 * (-10) = 0\n",
        "    \\end{align*}\n",
        "    $$\n",
        "\n",
        "-   We want start thinking about how people make decisions about uncertain outcomes and we do that using lotteries. Each lottery has to specify three elements:\n",
        "\n",
        "    -   events\n",
        "\n",
        "    -   the probability of those events and\n",
        "\n",
        "    -   payoffs associated with those events\n",
        ":::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "<div>\n",
        "\n",
        "-   Expected Utility Theory is a reformulation of our earlier result for uncertain outcomes.\n",
        "\n",
        "-   It states that when faced with risky prospects, agents choose with the prospect which maximizes their expected utility.\n",
        "\n",
        "-   Back to framing effects\n",
        "\n",
        "</div>\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "<div>\n",
        "\n",
        "## Activity Time\n",
        "\n",
        "</div>"
      ],
      "id": "6a346174"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}